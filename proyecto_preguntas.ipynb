{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto final KDD\n",
    "\n",
    "**Docente: Andrés Castillo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdución\n",
    "\n",
    "La estimación de los precios de la vivienda es esencial tanto para los propietarios como para los inversores, ya que ambos necesitan entender el valor de este activo inmobiliario. \n",
    "Para muchas personas, comprar una propiedad es una de las decisiones y compra más importantes en la vida. Además de la asequibilidad de una vivienda, otros factores, \n",
    "como la conveniencia del lugar y las perspectivas de inversión a largo plazo, también afectan\n",
    "el proceso de toma de decisiones.\n",
    "El mercado inmobiliario está expuesto a muchas fluctuaciones en los precios debido a las correlaciones existentes con muchas variables, algunas de las cuales no se pueden controlar\n",
    "o incluso pueden ser desconocidas. Los precios de las viviendas pueden aumentar rápidamente (o en algunos casos, también bajan muy rápido).\n",
    "Algunas aplicaciones para un banco son:\n",
    "- Originación: Establecer el valor comercial del inmueble a financiar utilizado para la aprobación final.\n",
    "- Retanqueo: Actualizar el valor comercial de garantía ya existente para aprobación de nuevos cupos de crédito.\n",
    "- Monitoreo portafolio garantías: Valoración del portafolio de las garantías para cumplimiento normativo y para el análisis de riesgos del colateral.\n",
    "- Normalización de cartera: Evaluar los préstamos existentes, evaluar los acuerdos de refinanciamiento Y daciones en pago.\n",
    "\n",
    "## Objetivo:\n",
    "\n",
    "El objetivo de este proyecto es que el estudiante aplique los temas vistos en la clase de Descubrimiento de Conocimiento para resolver un problema del mundo real, con datos reales. Lea cuidadosamente las instrucciones contenidas en el archivo \"descripcion_prueba.pdf\". Allí están los detalles iniciales de la prueba. Para este curso, se evaluará adicionalmente el desarrollo de los puntos de este notebook. \n",
    "\n",
    "Para resolver este problema, usted debe seguir las instrucciones especificas que se dan en cada parte del notebook. Al final, usted debe entregar una copia de este notebook junto con unas conclusiones finales que usted debe sacar y que deben estar contenidas al final del documento.\n",
    "\n",
    "Cómo es usual, para empezar, debemos importar todas las librerías que vamos a necesitar. Asegurese de instalar la librería XGBoost para su sistema operativo y todas las demás, hasta que no encuentre ningún error al correr la siguiente celda:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import argparse\n",
    "import glob\n",
    "from pandas import DataFrame\n",
    "import sklearn\n",
    "from sklearn import tree\n",
    "import xgboost\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora definimos la funciones que nos ayudarán a evaluar el desempeño de nuestro modelo. Justo las mismas que se usaron en nuestro último ejercicio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula el mean_absolute_percentage_error. El vector y_true no puede tener 0\n",
    "def mape(y_true, y_pred): \n",
    "    #y_true, y_pred = check_arrays(y_true, y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def plotScatterModel(aX, aY, bX, bY, model):\n",
    "    paY = model.predict(aX)\n",
    "    pbY = model.predict(bX)\n",
    "    #Print the score on the train data\n",
    "    print('R2')\n",
    "    print({'Training': model.score(trainXX, trainY), 'Test': model.score(testXX, testY) })\n",
    "\n",
    "    print('\\nMAPE')\n",
    "    print({'Training ': mape(trainY, paY), 'Test': mape(testY, pbY)})\n",
    "\n",
    "    # declarando un objeto tipo Figura para desarrollar los subplots\n",
    "    fig = plt.figure(figsize=(20, 8))\n",
    "\n",
    "    ax = fig.add_subplot(1,2,1)\n",
    "    plt.scatter(aY, paY, s = 0.1)\n",
    "    plt.title('Correlation in training set')\n",
    "\n",
    "\n",
    "    ax2 = fig.add_subplot(1,2,2)\n",
    "    plt.scatter(bY, pbY, s = 0.1)\n",
    "    plt.title('Correlation in test set')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Junto con este notebook, usted encontrará un conjunto de archivos con los datos de datos de entranamiento. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!ls data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar los datos que usaremos\n",
    "\n",
    "Como es un conjunto de datos pequeño podemos cargar todo en memoría y trabajar de esta manera. Solo usaremos los archivos entrenamiento_precios_vivienda.csv  y prueba_precios_vivienda.csv. Note que los datos del archivo prueba_precios_vivienda.csv no contienen la columna de los precios de la vivienda. La idea de este archivo, es que usted complete dicha columna con los predicciones resultantes de su modelo, y mediante un proceso de validación externo, la compañia calcula el desempeño de este. Esta es una práctica muy común en pruebas de este tipo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataTrain = pd.read_excel('data/entrenamiento_precios_vivienda.xlsx')\n",
    "#dataTest = pd.read_excel('data/testeo_precios_vivienda.xlsx')\n",
    "low_memory=False\n",
    "dataTrain = pd.read_csv('entrenamiento_precios_vivienda.csv', dtype=str)\n",
    "dataTest = pd.read_csv('prueba_precios_vivienda.csv', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignar el campo id como índice del dataframe\n",
    "dataTrain['id'] = pd.to_numeric(dataTrain['id'], errors='coerce')\n",
    "dataTest['id'] = pd.to_numeric(dataTest['id'], errors='coerce')\n",
    "\n",
    "dataTrain = dataTrain.set_index('id')\n",
    "dataTest =  dataTest.set_index('id')\n",
    "#dataTrain = dataTrain.drop(['id'], axis = 1)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "\n",
    "dataTrain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removemos todos los caracteres especiales y pasar todas las cadenas a mayúsculas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def stringCleanUpInPlace(dataX):\n",
    "    attributes = dataX.columns\n",
    "\n",
    "    for attribute in attributes:\n",
    "        if type(dataX[attribute].values[0]) == str:\n",
    "            dataX[[attribute]] = dataX[[attribute]].fillna('');\n",
    "            dataX[attribute] = [re.sub('[^A-Za-z0-9.,+\\-]+', '', row + '').upper() for row in dataX[attribute]]\n",
    "    \n",
    "    return dataX\n",
    "\n",
    "            \n",
    "stringCleanUpInPlace(dataTrain)\n",
    "stringCleanUpInPlace(dataTest)\n",
    "\n",
    "## Remove varias filas del conjunto de entranamiento que tienen las columnas del texto libre mal acotadas. Esto pasa\n",
    "## pero al final la fila tiene el mismo número de columnas que las otras, entonces no se cual es realmente el avaluo.\n",
    "## para evitar otros problemas, por ahora lo mejor es borrarlas\n",
    "print(dataTrain.shape)\n",
    "dataTrain = dataTrain[dataTrain['alcantarillado_en_el_predio'].str.len() < 3]\n",
    "dataTrain = dataTrain[dataTrain['numero_piso'].str.len() < 3]\n",
    "dataTrain = dataTrain[dataTrain['habitaciones'].str.len() < 3]\n",
    "dataTrain = dataTrain[dataTrain['estado_acabados_pisos'].str.len() < 15]\n",
    "dataTrain = dataTrain[dataTrain['metodo_valuacion_1'].str.len() < 20]\n",
    "dataTrain = dataTrain[dataTrain['estrato'].str.len() < 2]\n",
    "\n",
    "\n",
    "data = dataTrain.copy()\n",
    "\n",
    "print(dataTrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "dataTrain = data.copy()\n",
    "#dataTrain = dataTrain[dataTrain['estrato'].str.len() < 2]\n",
    "#print(dataTrain.shape)\n",
    "dataTrain.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificar los atributos según el tipo\n",
    "\n",
    "Esta es una de las partes más importantes del proceso y es aquí donde necesitamos mas conocimiento del negocio. Me he basado en el diccionario de datos que entregaron y de la interpretación que pude hacer de los demás atributos. Como se puede ver, no he usado todas las variables. En el listado está solo la mitad de todas las diponibles.\n",
    "\n",
    "Usualmente divido los atributos en numéricos, categóricos nominales y categóricos ordinales y texto no estructurado. Como no pienso usar los datos geoespaciales, voy a considerar por ahora la latitud y la longitud como variables numéricas.\n",
    "\n",
    "**Tarea**\n",
    "\n",
    "Usando la información disponible clasifique los atributos que usará para resolver el problema entre `numericColumns`, `factorColumns`, `levelColumns` y  `textColumns`\n",
    "\n",
    "Las columnas objetivo son: `'valor_total_avaluo', 'valor_uvr', 'valor_avaluo_en_uvr'`\n",
    "Aunque usaremos solo la primera realmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.api.types import CategoricalDtype\n",
    "\n",
    "numericColumns = ['area_privada', ...] # Completar\n",
    "\n",
    "factorColumns = ['objeto', 'sardineles_en_las_vias', ...] # Completar\n",
    "\n",
    "levelColumns = ['demanda_interes', ...] # Completar\n",
    "\n",
    "textColumns = ['descripcion_general_sector', ...] # Completar\n",
    "\n",
    "target = ['valor_total_avaluo', 'valor_uvr', 'valor_avaluo_en_uvr']\n",
    "\n",
    "\n",
    "def toDataTypesInPlace(dataX):\n",
    "    # Convert to numeric attributes\n",
    "    # Nothing to do in python. Numeric is the dafault\n",
    "    realNumericColumns = []\n",
    "    for col in numericColumns:\n",
    "        if  col in dataX.columns:\n",
    "            realNumericColumns.append(col)\n",
    "            if type(dataX[col].values[0]) == str:\n",
    "                dataX[col] = [re.sub(',', '.', row + '') for row in dataX[col]]\n",
    "                dataX[col] = pd.to_numeric(dataX[col], errors='coerce')\n",
    "\n",
    "    # loop to change each column to category type\n",
    "    for col in factorColumns:\n",
    "        if  col in dataX.columns:\n",
    "            cat_type = CategoricalDtype(categories = None, ordered = False)\n",
    "            dataX[col] = dataX[col].astype(dtype = cat_type)\n",
    "\n",
    "    # Conver to levels / Ordinals\n",
    "    #for col in levelColumns:\n",
    "    col = 'demanda_interes'\n",
    "    cat_type = CategoricalDtype(categories = [ 'NULA', 'DBIL', 'MEDIA', 'FUERTE'], ordered = True)\n",
    "    dataX[col] = dataX[col].astype(dtype = cat_type)\n",
    "\n",
    "    col = 'nivel_equipamiento_comercial'\n",
    "    cat_type = CategoricalDtype(categories = [ 'REGULARMALO', 'ENPROYECTO', 'BUENO',  'MUYBUENO'], ordered = True)\n",
    "    dataX[col] = dataX[col].astype(dtype = cat_type)\n",
    "\n",
    "    col = 'estrato'\n",
    "    cat_type = CategoricalDtype(categories = [ '0', '1', '2', '3', '4', '5', '6', '7'], ordered = True)\n",
    "    dataX[col] = dataX[col].astype(dtype = cat_type)\n",
    "    # Delete the textColumns. I dont have time to deal with it now\n",
    "    #dataTrain = dataTrain.drop(textColumns, axis=1)\n",
    "    print(len(dataX.columns))\n",
    "    dataX = dataX[factorColumns + levelColumns + realNumericColumns]\n",
    "    #dataTrain = dataTrain.drop(['barrio'], axis = 1)\n",
    "    print(len(dataX.columns))\n",
    "    return dataX\n",
    "\n",
    "dataTrain = toDataTypesInPlace(dataTrain)\n",
    "dataTest = toDataTypesInPlace(dataTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miremos las variables nominales\n",
    "\n",
    "Debemos hacer algo con el departamento, el municipio y el area_actividad. Talvez solo debemos considerar los principales valores de estas variables categóricas. He utilizado la visualización durante la curación de los datos. Esto me ha permitido saber que habían errores y así pude quitar todas la filas que estaban dañadas.\n",
    "\n",
    "**Tarea**\n",
    "\n",
    "Muestre diagramas tipo torta para una de las variables categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(30, 20))\n",
    "\n",
    "# Declarando las graficas de tipo Pie para Variables Categoricas\n",
    "x = 1\n",
    "for catAtt in factorColumns:\n",
    "    # Grafica de la Variable sex\n",
    "    #Completar aqui\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miremos las variables numéricas (solo la variable objetivo en este caso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataTrain[dataTrain['valor_total_avaluo'] < 1e9]\n",
    "dataTrain['valor_total_avaluo'].plot(kind='hist', rwidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es claro que hay unos outlayer que harán que nuestro proceso de predicción sea dificil. Lo mejor es eliminarlos. Por ahora simplemente elimino los registros con valores por encima de 1e9. También lo mejor es eliminar los registros con avaluos muy bajos. No creo que algo en realidad valga menos de $100.000 por ejemplo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTrain[dataTrain['valor_total_avaluo'] < 1e9]['valor_total_avaluo'].plot(kind='hist', rwidth=1)\n",
    "plt.show()\n",
    "print(sum(dataTrain['valor_total_avaluo'] > 1e9))\n",
    "print(sum(dataTrain['valor_total_avaluo'] <= 1000000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tarea**\n",
    "\n",
    "Removemos los ejemplos donde:\n",
    "* dataTrain['valor_total_avaluo'] < 1e9\n",
    "* dataTrain['valor_total_avaluo'] > 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTrain = # Completar\n",
    "dataTrain = # Completar\n",
    "dataTrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Miremos las variables ordinales\n",
    "\n",
    "**Tarea**\n",
    "\n",
    "Muestre diagramas tipo torta para una de las variables ordinales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(30, 60))\n",
    "x = 1\n",
    "for catAtt in levelColumns:\n",
    "    # Completar\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separamos los datos de entramiento \n",
    "\n",
    "En nuestro conjunto de entramiento, tenemos los atributos descriptivos y la variable de interés(avaluo de la vivienda) en la misma matriz. A continuación debe separar los datos en `dataX` y `dataY`\n",
    "\n",
    "**Tarea**\n",
    "\n",
    "Separar los datos de manera que en dataY solo tenga el atributo target[0] y en dataX todos los atributos que no hagan parte de la lista target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataY = # Completar\n",
    "dataX = # Completar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convertir factores a dummy y levels a numeric\n",
    "\n",
    "Ahora debemos convertir los atributos nominales y ordinales en variables numéricas. Adicionalmente debemos eleminar los datos con valores no definidos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataToNumeric(dataIn, factorColumns, levelColumns):\n",
    "    columns = dataIn.columns\n",
    "    for catAtt in factorColumns:\n",
    "        if catAtt in columns:\n",
    "            dummies = pd.get_dummies(dataIn[catAtt], prefix = catAtt)\n",
    "            dataIn = pd.concat([dataIn.drop(catAtt, axis = 1), dummies], axis = 1)\n",
    "\n",
    "    for catAtt in levelColumns:\n",
    "        if catAtt in columns:\n",
    "            dataIn[catAtt] = dataIn[catAtt].cat.codes\n",
    "    \n",
    "    return dataIn\n",
    "\n",
    "\n",
    "# Fill NAN in numerical attributes\n",
    "def fillNaNWithMeanInPlace(dataX):\n",
    "    foo = dataX.isnull().sum()\n",
    "    index = 0\n",
    "    for f in foo:\n",
    "        if f > 0:\n",
    "            colname = dataX.columns[index]\n",
    "            print(colname)\n",
    "            dataX[colname] = dataX[colname].fillna(dataX[colname].median())\n",
    "            #else:\n",
    "            #    dataX[colname] = dataX[colname].cat.add_categories('DESC')\n",
    "            #    dataX[colname] = dataX[colname].fillna('DESC')\n",
    "        index = index + 1\n",
    "    return dataX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tarea**\n",
    "\n",
    "Use las funciones definidas anteriormente para convertir todos los atributos a numéricos y para eliminar los datos faltantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = dataX.copy()\n",
    "        \n",
    "data2 = # Completar dataToNumeric(...)\n",
    "dataTest = # Completar dataToNumeric(...)\n",
    "\n",
    "data2 = # Completar fillNaNWithMeanInPlace(...)\n",
    "dataTest = # Completar fillNaNWithMeanInPlace(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tarea**\n",
    "\n",
    "Elimine del conjunto de entrenamiento y test las columnas 'Latitud' y 'Longitud'.\n",
    "\n",
    "Ayuda: Use la función drop con axis=1 del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = # Completar\n",
    "dataTest = # Completar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data2.shape)\n",
    "print(dataTest.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valores esperados:\n",
    "    \n",
    "```\n",
    "(9310, 859)\n",
    "(3175, 521)\n",
    "```\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primer experimento de datamining\n",
    "\n",
    "Ajustamos la escala de las variables antes de comenzar a probar modelos. Y vamos a fijar el mismo conjunto de entrenamiento y test para todos los modelos de aqui hacia abajo. Para validar el desempeño de nuestro modelo en datos desconocidos, partimos nuestro conjunto de entranmiento en 2:\n",
    "* Entranamiento: 75%\n",
    "* Validación: 25%\n",
    "\n",
    "Adicionalmente los datos x e y de entrenamiento y validación se deben estandarizar. \n",
    "\n",
    "**Tarea** \n",
    "\n",
    "Use la función `train_test_split` para partir los datos en entrenamiento y pruebsa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# NN is sensitive to data scale. We must normilize\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(data2)\n",
    "y = dataTrain[target[0]] / 1e9\n",
    "\n",
    "# Se divide el set de datos en dos conjuntos train y test\n",
    "trainX, testX, trainY, testY = train_test_split(data2, y, test_size = 0.25)\n",
    "\n",
    "# Don't cheat - fit only on training data\n",
    "trainXX = scaler.transform(trainX)  \n",
    "# apply same transformation to test data\n",
    "testXX = scaler.transform(testX)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Salida esperada**\n",
    "\n",
    "```\n",
    "(6982, 859)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probemos con un modelo que se pueda interpretar. \n",
    "\n",
    "La regresion lineal es el método más sencillo que podemos usar. Use la clase `LinearRegression` de `sklearn.linear_model` y verifique los resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "modelLM = LinearRegression()\n",
    "modelLM.fit(trainXX, trainY);\n",
    "\n",
    "\n",
    "plotScatterModel(trainXX, trainY, testXX, testY, modelLM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Claramente un modelo lineal no resuelve el problema. Entonces si queremos poder interpretar el resultado vamos a tener que probar con otra cosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regression.\n",
    "\n",
    "**Tarea**\n",
    "\n",
    "Una alternativa para obtener un modelo interpretable es usando árboles como modelo de regresión y preguntar por la importancia de las características. Use la clase`DecisionTreeRegressor` de `sklearn.tree`\n",
    "\n",
    "Siguiendo el mismo esquema del modelo anterior implemente las intrucciones de la celda siguiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "#Completar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con estas líneas debería poder mostrar cual es la importancia de cada uno de los atributos del conjunto de datos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = trainX.columns[modelDTR.feature_importances_> 0]\n",
    "importances = modelDTR.feature_importances_[modelDTR.feature_importances_> 0]\n",
    "reportOfAttributes = pd.DataFrame({'attribute': attributes, 'importances': importances})\n",
    "reportOfAttributes = reportOfAttributes.sort_values(by = 'importances',  ascending=False)\n",
    "reportOfAttributes = reportOfAttributes.set_index('attribute')\n",
    "reportOfAttributes.plot(kind='bar', figsize=(20, 5)).set_title('Feature importance ADA')\n",
    "sum(modelDTR.feature_importances_> 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBOOST\n",
    "\n",
    "**Tarea**\n",
    "\n",
    "Ahora entrene un modelo `XGBOOST`. Use estos parámetros: \n",
    "\n",
    "* objective='reg:squarederror\n",
    "* colsample_bytree=0.2\n",
    "* learning_rate=0.1\n",
    "* max_depth=5\n",
    "* alpha=5\n",
    "* n_estimators=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tarea**\n",
    "\n",
    "Nuevamente, muestre la importancia de cada uno de los atributos según el algoritmo XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADABoost\n",
    "\n",
    "Entrene un modelo ADABoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADABoost\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tarea**\n",
    "\n",
    "Muestre la importancia de los atributos para el modelo ADABoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest regressor\n",
    "\n",
    "**Tarea**\n",
    "\n",
    "Entrene un modelo de regresión Random Forest. Use la clase `RandomForestRegressor` de `sklearn.ensemble`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RadomForest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Completar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tarea**\n",
    "\n",
    "Muestre la importancia de los atributos para el modelo random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Completar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red neuronal\n",
    "\n",
    "**Tarea**\n",
    "\n",
    "Entrene una red neuronal para este problema. Busque de manera libre los parámetros que mejor le funcionen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Completar \n",
    "\n",
    "#Print report\n",
    "plotScatterModel(trainXX, trainY, testXX, testY, model3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selección de atributos\n",
    "\n",
    "**Tarea**\n",
    "\n",
    "Ahora, para hacer que el modelo XGBoost se demore menos entrenando, use solo los mejores atributos del modelo ADABoost, como atributos de entrada al modelo XGBoost. \n",
    "\n",
    "Para esto puede seleccionar las columnas de la siguiente manera:\n",
    "\n",
    "```py\n",
    "data3 = data2.loc[:, data2.columns[modelAda.feature_importances_> 0].values]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usemos los mejores atributos del modelo ADABoost para entrenar el resto de modelos de aqui en adelante\n",
    "data2.shape\n",
    "data3 = # Completar\n",
    "data3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(data3)\n",
    "y = dataTrain[target[0]] / 1e9\n",
    "\n",
    "# Se divide el set de datos en dos conjuntos train y test\n",
    "trainX, testX, trainY, testY = train_test_split(data3, y, test_size = 0.25)\n",
    "\n",
    "# Don't cheat - fit only on training data\n",
    "trainXX = scaler.transform(trainX)  \n",
    "# apply same transformation to test data\n",
    "testXX = scaler.transform(testX)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tarea**\n",
    "\n",
    "Entrene un nuevo modelo XGBoost con el nuevo conjunto de datos. Compare los resultados y el tiempo requerido para el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg2 = xgboost.XGBRegressor(objective='reg:squarederror', colsample_bytree=0.2, learning_rate=0.1, max_depth=5, alpha=5, n_estimators=200)\n",
    "xg_reg2.fit(trainXX, trainY)\n",
    "plotScatterModel(trainXX, trainY, testXX, testY, xg_reg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predecir\n",
    "\n",
    "Use el mejor modelo obtenido para predecir los precios de todas la viviendas del conjunto de `dataTest`. Guarde el resultado en un archivo 'predicciones.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para entregar, deberá poner en una carpeta este notebook, junto con el archivo de las las predicciones para el conjunto de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
